
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Getting Started &#8212; pypal 0+untagged.212.g4af8189.dirty documentation</title>

  <link rel="stylesheet" href="_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">


  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">



  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">


    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />

  <link rel="preload" as="script" href="_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorials" href="tutorials.html" />
    <link rel="prev" title="PyPAL: Pareto active learning for Python" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">

    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">


    <a class="navbar-brand" href="index.html">
      <img src="_static/pypal_logo.png" class="logo" alt="logo">
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">


        <li class="nav-item active">
            <a class="nav-link" href="">Getting Started</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="tutorials.html">Tutorials</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="background.html">Background</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="api.html">The PyPAL API reference</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="developer_notes.html">Developer notes</a>
        </li>


      </ul>




      <ul class="navbar-nav">

          <li class="nav-item">
            <a class="nav-link" href="https://github.com/kjappelbaum/pypal" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>


      </ul>
    </div>
</div>
    </nav>


    <div class="container-xl">
      <div class="row">

          <div class="col-12 col-md-3 bd-sidebar">

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>


<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

  <div class="bd-toc-item active">


  <ul class="nav bd-sidenav">













    </ul>

</nav>
          </div>



          <div class="d-none d-xl-block col-xl-2 bd-toc">

<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">

        <li class="nav-item toc-entry toc-h2">
            <a href="#installation" class="nav-link">Installation</a>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#which-class-do-i-use" class="nav-link">Which class do i use?</a>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#running-an-active-learning-experiment" class="nav-link">Running an active learning experiment</a><ul class="nav section-nav flex-column">

        <li class="nav-item toc-entry toc-h3">
            <a href="#hyperparameter-optimization" class="nav-link">Hyperparameter optimization</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#logging" class="nav-link">Logging</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#properties-of-the-pal-object" class="nav-link">Properties of the PAL object</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#exploring-a-space-where-all-objectives-are-known" class="nav-link">Exploring a space where all objectives are known</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#batch-sampling" class="nav-link">Batch sampling</a>
        </li>

            </ul>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#caveats-and-tricks-with-gaussian-processes" class="nav-link">Caveats and tricks with Gaussian processes</a>
        </li>

    </ul>
</nav>



          </div>



          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

              <div>

  <div class="section" id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>PyPAL can be installed from <cite>PyPi</cite> using</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pypal</span>
</pre></div>
</div>
<p>We recommend installing PyPAL in a dedicated <a class="reference external" href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a> or <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">conda environment</a>.</p>
<p>The latest version of PyPAL can be installed from GitHub using</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">kjappelbaum</span><span class="o">/</span><span class="n">pypal</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</div>
<div class="section" id="which-class-do-i-use">
<h2>Which class do i use?<a class="headerlink" href="#which-class-do-i-use" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>For Gaussian processes built with <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> use <a class="reference internal" href="api.html#pypal.pal.pal_sklearn.PALSklearn" title="pypal.pal.pal_sklearn.PALSklearn"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_sklearn.PALSklearn</span></code></a></p></li>
<li><p>For Gaussian processes built with <code class="code docutils literal notranslate"><span class="pre">GPy</span></code> use <a class="reference internal" href="api.html#pypal.pal.pal_gpy.PALGPy" title="pypal.pal.pal_gpy.PALGPy"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_gpy.PALGPy</span></code></a></p></li>
<li><p>For coregionalized Gaussian processes (built with <code class="code docutils literal notranslate"><span class="pre">GPy</span></code>) use <a class="reference internal" href="api.html#pypal.pal.pal_coregionalized.PALCoregionalized" title="pypal.pal.pal_coregionalized.PALCoregionalized"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_coregionalized.PALCoregionalized</span></code></a></p></li>
<li><p>For quantile regression using <code class="code docutils literal notranslate"><span class="pre">LightGBM</span></code> gradient boosted decision trees use <a class="reference internal" href="api.html#pypal.pal.pal_gbdt.PALGBDT" title="pypal.pal.pal_gbdt.PALGBDT"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_gbdt.PALGBDT</span></code></a></p></li>
</ul>
<p>If your favorite model is not listed, you can easily implement it yourself (see <a class="reference internal" href="developer_notes.html#new-pal-class"><span class="std std-ref">Implementing a new PAL class</span></a>)!</p>
</div>
<div class="section" id="running-an-active-learning-experiment">
<h2>Running an active learning experiment<a class="headerlink" href="#running-an-active-learning-experiment" title="Permalink to this headline">¶</a></h2>
<p>The <cite>examples</cite> directory contains a <a class="reference external" href="https://github.com/kjappelbaum/pypal/blob/master/examples/test_pal.ipynb">Jupyter notebook with an example</a> that can also be run on MyBinder.</p>
<p>If using a Gaussian process model built with <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> or <code class="code docutils literal notranslate"><span class="pre">GPy</span></code> we recommend using a pre-built class such as <a class="reference internal" href="api.html#pypal.pal.pal_sklearn.PALSklearn" title="pypal.pal.pal_sklearn.PALSklearn"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_sklearn.PALSklearn</span></code></a>,  <a class="reference internal" href="api.html#pypal.pal.pal_coregionalized.PALCoregionalized" title="pypal.pal.pal_coregionalized.PALCoregionalized"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_coregionalized.PALCoregionalized</span></code></a>,  <a class="reference internal" href="api.html#pypal.pal.pal_gpy.PALGPy" title="pypal.pal.pal_gpy.PALGPy"><code class="xref py py-class docutils literal notranslate"><span class="pre">pypal.pal.pal_gpy.PALGPy</span></code></a> and following the subsequent steps (for more details on which class to use see <a class="reference internal" href="#which-class-do-i-use"><span class="std std-ref">Which class do i use?</span></a>):</p>
<ol class="arabic">
<li><p>For each objective create a model (if using a coregionalized Gaussian process model, only one model needs to be created)</p></li>
<li><p>Sample a few initial points from the design space. We provide the <a class="reference internal" href="api.html#pypal.pal.utils.get_maxmin_samples" title="pypal.pal.utils.get_maxmin_samples"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pypal.pal.utils.get_maxmin_samples()</span></code></a> or <a class="reference internal" href="api.html#pypal.pal.utils.get_kmeans_samples" title="pypal.pal.utils.get_kmeans_samples"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pypal.pal.utils.get_kmeans_samples()</span></code></a> utilities that can help with the sampling. Our code assumes that <code class="code docutils literal notranslate"><span class="pre">X</span></code> is a <code class="code docutils literal notranslate"><span class="pre">np.array</span></code>.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">get_kmeans_samples</span><span class="p">,</span> <span class="n">get_maxmin_samples</span>

<span class="c1"># This selects the 10 points closest to the centroids of a k=10 means clustering</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">get_kmeans_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># This selects the 10 farthest points in feature space</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">get_maxmin_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Now we can initialize the instance of one <code class="code docutils literal notranslate"><span class="pre">PAL</span></code> class. If using a <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> Gaussian process model, we would use</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALSklearn</span>

<span class="c1"># Each of these models is an instance of sklearn.gaussian_process.GaussianProcessRegressor</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpr0</span><span class="p">,</span> <span class="n">gpr1</span><span class="p">,</span> <span class="n">gpr2</span><span class="p">]</span>

<span class="c1"># We always need to provide the feature matrix (X), a list of models, and the number of objectives</span>
<span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Now, we can also feed in the first measurements</span>
<span class="c1"># this here assumes that we have all measurements for y and we now</span>
<span class="c1"># provide those which are present in the indices array</span>
<span class="n">palinstance</span><span class="o">.</span><span class="n">update_train_set</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>

<span class="c1"># Now we can run one step</span>
<span class="n">next_idx</span> <span class="o">=</span> <span class="n">palinstance</span><span class="o">.</span><span class="n">run_one_step</span><span class="p">()</span>
</pre></div>
</div>
<p>At this level, we have a range of different optional arguements we can set.</p>
<ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">epsilon</span></code>: one <span class="math notranslate nohighlight">\(\epsilon\)</span> per dimension in a <code class="code docutils literal notranslate"><span class="pre">np.ndarray</span></code>. This can be used to set different tolerances for each objective. Note that <span class="math notranslate nohighlight">\(\epsilon_i \in [0,1]\)</span>.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">delta</span></code>: the <span class="math notranslate nohighlight">\(\delta\)</span> hyperparameter (<span class="math notranslate nohighlight">\(\delta \in [0,1]\)</span>). Increasing this value will speed up the convergence.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">beta_scale</span></code>: an empirical scaling parameter for <span class="math notranslate nohighlight">\(beta\)</span>. The theoretical guarantees in the PAL paper are derived for this parameter set to 1. But in practice, a much faster convergence can be achieved by setting it to a number <span class="math notranslate nohighlight">\(0&lt; \beta_\mathrm{scale} \ll 1\)</span>.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">goal</span></code>: By default, PyPAL assumes that the goal is to maximize every objective. If this is not the case, this argument can be set using a list of “min” and “max” strings, with “min” specifying whether to minimize the ith objective and “max” indicating whether to maximize this objective.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">coef_var_threshold</span></code>: By default, PyPAL will not consider points with a coefficient of variation <span class="math notranslate nohighlight">\(\ge 3\)</span> for the classification step of the algorithm. This is meant to avoid classifying design points for which the model is entirely unsure. This tends to happen when a model is severely overfit on the training data (i.e., the training data uncertainties are very low, whereas the prediction uncertainties are very high). To change this setting, reduce this value to make the check tighter or increase it to avoid this check (as in the original implementation).</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>In the case of missing observations, i.e., only two of three outputs are measured, report the missing observations as <code class="code docutils literal notranslate"><span class="pre">np.nan</span></code>. The call could look like</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">palinstance</span><span class="o">.</span><span class="n">update_train_set</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
</pre></div>
</div>
<p>for a case in which we performed measurements for samples with index 1 and 2 of our design space, but did not measure the first target for sample 2.</p>
<div class="section" id="hyperparameter-optimization">
<h3>Hyperparameter optimization<a class="headerlink" href="#hyperparameter-optimization" title="Permalink to this headline">¶</a></h3>
<p>Usually, the hyperparameters of a machine learning model, in particular the kernel hyperparameters of a Gaussian process regression model, should be optimized as new training data is added.
However, since this is usually a computationally expensive process, it may not be desirable to perform this at every iteration of the active learning process. The iteration frequency of the hyperparameter optimization is internally set by the <code class="code docutils literal notranslate"><span class="pre">_should_optimize_hyperparameters</span></code> function, which by default uses a schedule that optimizes the hyperparameter every 10th iteration. This behavior can be changed by override this function.</p>
</div>
<div class="section" id="logging">
<h3>Logging<a class="headerlink" href="#logging" title="Permalink to this headline">¶</a></h3>
<p>Basic information such as the current iteration and the classification status are logged and can be viewed by printing the <code class="code docutils literal notranslate"><span class="pre">PAL</span></code> object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">palinstance</span><span class="p">)</span>

<span class="c1"># returns: pypal at iteration 1. 10 Pareto optimal points, 1304 discarded points, 200 unclassified points.</span>
</pre></div>
</div>
<p>We also provide calculation of the hypervolume enclosed by the Pareto front with the function <a class="reference internal" href="api.html#pypal.pal.utils.get_hypervolume" title="pypal.pal.utils.get_hypervolume"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pypal.pal.utils.get_hypervolume()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hv</span> <span class="o">=</span> <span class="n">get_hypervolume</span><span class="p">(</span><span class="n">palinstance</span><span class="o">.</span><span class="n">means</span><span class="p">[</span><span class="n">palinstance</span><span class="o">.</span><span class="n">pareto_optimal</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="properties-of-the-pal-object">
<h3>Properties of the PAL object<a class="headerlink" href="#properties-of-the-pal-object" title="Permalink to this headline">¶</a></h3>
<p>For debugging there are some properties and attributes of the <cite>PAL</cite> class that can be used to inspect the progress of the active learning loop.</p>
<ul class="simple">
<li><dl class="simple">
<dt>get the points in the design space, <code class="code docutils literal notranslate"><span class="pre">x</span></code>:</dt><dd><ul>
<li><p><code class="code docutils literal notranslate"><span class="pre">design_space</span></code> returns the full design space matrix</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">pareto_optimal_points</span></code>: returns the points that are classified as Pareto-efficient</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">sampled_points</span></code>: returns the points that have been sampled</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">discarded_points</span></code>: returns the points that have been discarded</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>get the indicies of Pareto efficent, sampled,  discarded, and unclassified points with <code class="code docutils literal notranslate"><span class="pre">pareto_optimal_indices</span></code>, <code class="code docutils literal notranslate"><span class="pre">sampled_indices</span></code>, <code class="code docutils literal notranslate"><span class="pre">discarded_indices</span></code>, and <code class="code docutils literal notranslate"><span class="pre">unclassified_indices</span></code></p></li>
<li><p>similarly, the number of points in the different classes can be obtained using <code class="code docutils literal notranslate"><span class="pre">number_pareto_optimal_points</span></code>, <code class="code docutils literal notranslate"><span class="pre">number_discarded_points</span></code>, <code class="code docutils literal notranslate"><span class="pre">number_unclassified_points</span></code>, and <code class="code docutils literal notranslate"><span class="pre">number_sampled_points</span></code></p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">hyperrectangle_size</span></code> returns the sizes of the hyperrectangles, i.e., the weights that are used in the sampling step</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">means</span></code> and <code class="code docutils literal notranslate"><span class="pre">std</span></code> contain the predictions of the model</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">sampled</span></code> is a mask array. In case one objective has not been measured its cell is <code class="code docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</div>
<div class="section" id="exploring-a-space-where-all-objectives-are-known">
<h3>Exploring a space where all objectives are known<a class="headerlink" href="#exploring-a-space-where-all-objectives-are-known" title="Permalink to this headline">¶</a></h3>
<p>In some cases, we may already posess all measurements, but would like to run PAL with different settings to test how the algorithm performs.
In this case, we provide the <a class="reference internal" href="api.html#pypal.pal.utils.exhaust_loop" title="pypal.pal.utils.exhaust_loop"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pypal.pal.utils.exhaust_loop()</span></code></a> wrapper.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALSklearn</span><span class="p">,</span> <span class="n">exhaust_loop</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpr0</span><span class="p">,</span> <span class="n">gpr1</span><span class="p">,</span> <span class="n">gpr2</span><span class="p">]</span>
<span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">exhaust_loop</span><span class="p">(</span><span class="n">palinstance</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This will continue calling <code class="code docutils literal notranslate"><span class="pre">run_one_step()</span></code> until there is no unclassified sample left.</p>
</div>
<div class="section" id="batch-sampling">
<h3>Batch sampling<a class="headerlink" href="#batch-sampling" title="Permalink to this headline">¶</a></h3>
<p>By default, the <code class="code docutils literal notranslate"><span class="pre">run_one_step</span></code> function of the PAL classes will return a <code class="code docutils literal notranslate"><span class="pre">np.ndarray</span></code> with only one index for the point in the design space for which the next experiment should be performed. In some situations, it may be more practical to run multiple experiments as batches before running the next active learning iteration. In such cases, we provide the <code class="code docutils literal notranslate"><span class="pre">batch_size</span></code> argument which can be set to an integer greater than one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">next_idx</span> <span class="o">=</span> <span class="n">palinstance</span><span class="o">.</span><span class="n">run_one_step</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># next_idx will be a np.array of length 10</span>
</pre></div>
</div>
<p>Note that the <cite>exhaust_loop</cite> also supports the <cite>batch_size</cite> keyword argument</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># sample always 10 points and do this until there is no unclassified</span>
<span class="c1"># point left</span>
<span class="n">exhaust_loop</span><span class="p">(</span><span class="n">palinstance</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="caveats-and-tricks-with-gaussian-processes">
<h2>Caveats and tricks with Gaussian processes<a class="headerlink" href="#caveats-and-tricks-with-gaussian-processes" title="Permalink to this headline">¶</a></h2>
<p>One caveat to keep in mind is that <span class="math notranslate nohighlight">\(\epsilon\)</span>-PAL will not work if the predictive variance does not make sense. For example, when the model is overconfident and the uncertainties for the training set is significantly lower than those for the predicted set. In this case, PyPAL will untimely, and often incorrectly, label the design points. An example situation where the predictions for an overconfident model due to a training set that excludes a part of design space is shown in the figure below</p>
<a class="reference internal image-reference" href="_images/overconfident_model.png"><img alt="Example of the predictions of an overconfident GPR model" src="_images/overconfident_model.png" style="width: 600px;" /></a>
<p>This problem is exacerbated in conjunction with <span class="math notranslate nohighlight">\(\beta_\mathrm{scale} &lt; 1\)</span>. To make the model more robust we suggest trying:</p>
<ul class="simple">
<li><p>to set reasonable bounds on the length scale parameters</p></li>
<li><p>to increase the regularization parameter/noise kernel (<code class="code docutils literal notranslate"><span class="pre">alpha</span></code> in <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code>)</p></li>
<li><p>to increase the number of data points, especially the coverage of the design space</p></li>
<li><p><a class="reference external" href="https://www.cs.toronto.edu/~duvenaud/cookbook/">to use a kernel that suits the problem</a></p></li>
<li><p>to turn off ARD. Automatic relevance determination (ARD) might increase the predictive performance, but also makes the model more prone to overfitting</p></li>
</ul>
<p>We also recommend to cross-validate the Gaussian process models and to check that the predicted variances make sense. When performing cross-validation, make sure that the index provided to PyPAL is the same size as the cross-validation folds.
By default, the code will run a simple cross-validation only on the first iteration and provide a warning if the mean absolute error is above the mean standard deviation. The warning will look something like</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">mean</span> <span class="n">absolute</span> <span class="n">error</span> <span class="ow">in</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span> <span class="ow">is</span> <span class="mf">64.29</span><span class="p">,</span> <span class="n">the</span> <span class="n">mean</span> <span class="n">variance</span> <span class="ow">is</span> <span class="mf">0.36</span><span class="o">.</span>
<span class="n">Your</span> <span class="n">model</span> <span class="n">might</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">predictive</span> <span class="ow">and</span><span class="o">/</span><span class="ow">or</span> <span class="n">overconfident</span><span class="o">.</span>
<span class="n">In</span> <span class="n">the</span> <span class="n">docs</span><span class="p">,</span> <span class="n">you</span> <span class="n">find</span> <span class="n">hints</span> <span class="n">on</span> <span class="n">how</span> <span class="n">to</span> <span class="n">make</span> <span class="n">GPRs</span> <span class="n">more</span> <span class="n">robust</span><span class="o">.</span>
</pre></div>
</div>
<p>This behavior can changed with the cross-validation test being performed more frequently by overriding the <code class="code docutils literal notranslate"><span class="pre">should_run_crossvalidation</span></code> function.</p>
<p>Another way to detect overfitting is to use :py:func:<a href="#id1"><span class="problematic" id="id2">`</span></a>pypal.plotting.make_jointplot`function from the plotting subpackage. This function will plot all objectives against each other (with errorbars and different classes indicated with colors) and histograms of the objectives on the diagonal. If the majority of predicted points tend to overlap one another and get discarded by PyPAL, this may suggest that the surrogate model is overfitted.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal.plotting</span> <span class="kn">import</span> <span class="n">make_jointplot</span>

<span class="c1"># palinstance is a instance of a PAL class after</span>
<span class="c1"># calling run_one_step</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">make_jointplot</span><span class="p">(</span><span class="n">palinstance</span><span class="o">.</span><span class="n">means</span><span class="p">,</span> <span class="n">palinstance</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/jointplot_example.png"><img alt="Example of the output of make_jointplot" src="_images/jointplot_example.png" style="width: 600px;" /></a>
</div>
</div>


              </div>


              <div class='prev-next-bottom'>

    <a class='left-prev' id="prev-link" href="index.html" title="previous page">PyPAL: Pareto active learning for Python</a>
    <a class='right-next' id="next-link" href="tutorials.html" title="next page">Tutorials</a>

              </div>

          </main>


      </div>
    </div>


  <script src="_static/js/index.30270b6e4c972e43c488.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Kevin Maik Jablonka, Brian Yoo, Berend Smit.<br/>
    </p>
  </div>
</footer>
  </body>
</html>
