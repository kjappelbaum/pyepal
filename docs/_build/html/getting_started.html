
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Getting Started &#8212; pypal 0+untagged.166.ga7731c9.dirty documentation</title>

  <link rel="stylesheet" href="_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">


  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">



  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">


    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  <link rel="preload" as="script" href="_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Background" href="background.html" />
    <link rel="prev" title="pypal: Pareto active learning for Python" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">

    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">


    <a class="navbar-brand" href="index.html">
      <img src="_static/pypal_logo.png" class="logo" alt="logo">
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">


        <li class="nav-item active">
            <a class="nav-link" href="">Getting Started</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="background.html">Background</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="developer_notes.html">Developer notes</a>
        </li>

        <li class="nav-item ">
            <a class="nav-link" href="api.html">The pypal API reference</a>
        </li>


      </ul>




      <ul class="navbar-nav">

          <li class="nav-item">
            <a class="nav-link" href="https://github.com/kjappelbaum/pypal" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>


      </ul>
    </div>
</div>
    </nav>


    <div class="container-xl">
      <div class="row">

          <div class="col-12 col-md-3 bd-sidebar">

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>


<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

  <div class="bd-toc-item active">


  <ul class="nav bd-sidenav">











    </ul>

</nav>
          </div>



          <div class="d-none d-xl-block col-xl-2 bd-toc">

<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">

        <li class="nav-item toc-entry toc-h2">
            <a href="#installation" class="nav-link">Installation</a>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#running-an-active-learning-experiment" class="nav-link">Running an active learning experiment</a><ul class="nav section-nav flex-column">

        <li class="nav-item toc-entry toc-h3">
            <a href="#hyperparameter-optimization" class="nav-link">Hyperparameter optimization</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#logging" class="nav-link">Logging</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#exploring-a-space-where-all-objectives-are-known" class="nav-link">Exploring a space where all objectives are known</a>
        </li>

        <li class="nav-item toc-entry toc-h3">
            <a href="#batch-sampling" class="nav-link">Batch sampling</a>
        </li>

            </ul>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#caveats-and-tricks-with-gaussian-processes" class="nav-link">Caveats and tricks with Gaussian processes</a>
        </li>

        <li class="nav-item toc-entry toc-h2">
            <a href="#implementing-a-new-pal-class" class="nav-link">Implementing a new PAL class</a>
        </li>

    </ul>
</nav>



          </div>



          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

              <div>

  <div class="section" id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>You can install <cite>pypal</cite> from <cite>PyPi</cite> using</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pypal</span>
</pre></div>
</div>
<p>We recommend that you install <cite>pypal</cite> in a dedicated <a class="reference external" href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a> or <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">conda environment</a>.</p>
<p>If you want to use the latest version from GitHub, you can install it using</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">kjappelbaum</span><span class="o">/</span><span class="n">pypal</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</div>
<div class="section" id="running-an-active-learning-experiment">
<h2>Running an active learning experiment<a class="headerlink" href="#running-an-active-learning-experiment" title="Permalink to this headline">¶</a></h2>
<p>The <cite>examples</cite> directory contains a <a class="reference external" href="https://github.com/kjappelbaum/pypal/blob/master/examples/test_pal.ipynb">Jupyter notebook with an example</a> that you can also run on MyBinder.</p>
<p>If you use a Gaussian process model built with <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> or <code class="code docutils literal notranslate"><span class="pre">GPy</span></code> you can use a pre-built class and follow the following steps:</p>
<ol class="arabic">
<li><p>For each objective create a model (if you want to use a coregionalized model you, of course, only need to create one)</p></li>
<li><p>Sample a few initial points from your design space. In practice, you can use the <code class="code docutils literal notranslate"><span class="pre">get_maxmin_samples</span></code> or <code class="code docutils literal notranslate"><span class="pre">get_kmeans_samples</span></code> utilities for that. Assuming that <code class="code docutils literal notranslate"><span class="pre">X</span></code> is a <code class="code docutils literal notranslate"><span class="pre">np.array</span></code> if the descriptors/features</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">get_kmeans_samples</span><span class="p">,</span> <span class="n">get_maxmin_samples</span>

<span class="c1"># This selects the 10 points closest to the centroids of a k=10 means clustering</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">get_kmeans_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># This selects the 10 farthest points in feature space</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">get_maxmin_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Now, you can intialize the instance of one <code class="code docutils literal notranslate"><span class="pre">PAL</span></code> class. If we use a <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> Gaussian process model, we would use</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALSklearn</span>

<span class="c1"># Each of these models is an instance of sklearn.gaussian_process.GaussianProcessRegressor</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpr0</span><span class="p">,</span> <span class="n">gpr1</span><span class="p">,</span> <span class="n">gpr2</span><span class="p">]</span>

<span class="c1"># We always need to provide the feature matrix (X), a list of models, and the number of objectives</span>
<span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Now, we can also feed in the first measurements</span>
<span class="c1"># this here assumes that in y you have all measurements and you now</span>
<span class="c1"># provide the ones which index is in the indices array</span>
<span class="n">palinstance</span><span class="o">.</span><span class="n">update_train_set</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>

<span class="c1"># Now you can run one step</span>
<span class="n">next_idx</span> <span class="o">=</span> <span class="n">palinstance</span><span class="o">.</span><span class="n">run_one_step</span><span class="p">()</span>
</pre></div>
</div>
<p>At this level you have a range of different options you can set.</p>
<ul>
<li><p><code class="code docutils literal notranslate"><span class="pre">epsilon</span></code>: in a <code class="code docutils literal notranslate"><span class="pre">np.ndarray</span></code> you can provide one <span class="math notranslate nohighlight">\(\epsilon\)</span> per dimension. This allows you to set looser tolerance for some objectives. Note that <span class="math notranslate nohighlight">\(\epsilon_i \in [0,1]\)</span>.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">delta</span></code>: allows you to specify the <span class="math notranslate nohighlight">\(\delta\)</span> hyperparameter (<span class="math notranslate nohighlight">\(\delta \in [0,1]\)</span>). Increasing this value will speed up the convergence.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">beta_scale</span></code>: allows you to provide an empirical scaling parameter for beta. The theoretical guarantees in the PAL paper are derived for this parameter set to 1. But in practice, you can achieve much faster convergence by setting it to a number <span class="math notranslate nohighlight">\(0&lt; \beta_\mathrm{scale} \ll 1\)</span>. As shown in the figure below, <span class="math notranslate nohighlight">\(\beta\)</span> depends on <span class="math notranslate nohighlight">\(\delta\)</span> and scaling beta down will drastically reduce the size of the uncertainity rectangles</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/beta.png"><img alt="Beta as function of hyperparameters" src="_images/beta.png" style="width: 600px;" /></a>
</div></blockquote>
</li>
<li><p><code class="code docutils literal notranslate"><span class="pre">goal</span></code>: By default, <cite>pypal</cite> assumes that you want to maximize every objective. If this is not the case, you can set the <code class="code docutils literal notranslate"><span class="pre">goal</span></code> argument using a list of “min” and “max”, using “min” to specify that you want to minimize the ith objective and “max” to indicate that you want to maximize this objective.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>In case you have missing observations, i.e., you measured only two of three outputs at sometimes you need to report the missing observations as <code class="code docutils literal notranslate"><span class="pre">np.nan</span></code>, i.e., the call could look like</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">palinstance</span><span class="o">.</span><span class="n">update_train_set</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
<p>for a case in which we performed measurements for samples 1 and 2 of our design space but didn’t measure the first target for sample 2.</p>
<div class="section" id="hyperparameter-optimization">
<h3>Hyperparameter optimization<a class="headerlink" href="#hyperparameter-optimization" title="Permalink to this headline">¶</a></h3>
<p>Usually, the hyperparameters of a machine learning model should be optimized as new training data is added, in particular the kernel hyperparameters of a Gaussian process regression model. But since this is usually a computationally expensive process, you do not want to do this every iteration. The timing of the hyperparameter optimization is internally set by the <code class="code docutils literal notranslate"><span class="pre">_should_optimize_hyperparameter</span></code> function that by default uses a schedule that will optimize the hyperparameter every 10th iteration. If you want to change this behavior, you can override this function.</p>
</div>
<div class="section" id="logging">
<h3>Logging<a class="headerlink" href="#logging" title="Permalink to this headline">¶</a></h3>
<p>You will see basic information like the current iteration and the classification status if you print the <code class="code docutils literal notranslate"><span class="pre">PAL</span></code> object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">palinstance</span><span class="p">)</span>

<span class="c1"># returns: pypal at iteration 1. 10 Pareto optimal points, 1304 discarded points, 200 unclassified points.</span>
</pre></div>
</div>
<p>In case you want to also know the hypervolume, you can use the <code class="code docutils literal notranslate"><span class="pre">get_hypervolume</span></code> function</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hv</span> <span class="o">=</span> <span class="n">get_hypervolume</span><span class="p">(</span><span class="n">palinstance</span><span class="o">.</span><span class="n">means</span><span class="p">[</span><span class="n">palinstance</span><span class="o">.</span><span class="n">pareto_optimal</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="exploring-a-space-where-all-objectives-are-known">
<h3>Exploring a space where all objectives are known<a class="headerlink" href="#exploring-a-space-where-all-objectives-are-known" title="Permalink to this headline">¶</a></h3>
<p>In some cases, you already know all measurements you may want to run PAL with different settings and test how the algorithm performs.
In this case you can use the <code class="code docutils literal notranslate"><span class="pre">exhaust_loop</span></code> wrapper.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALSklearn</span><span class="p">,</span> <span class="n">exhaust_loop</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpr0</span><span class="p">,</span> <span class="n">gpr1</span><span class="p">,</span> <span class="n">gpr2</span><span class="p">]</span>
<span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">exhaust_loop</span><span class="p">(</span><span class="n">palinstance</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This will continue calling <code class="code docutils literal notranslate"><span class="pre">run_one_step()</span></code> until there is no unclassified sample left.</p>
</div>
<div class="section" id="batch-sampling">
<h3>Batch sampling<a class="headerlink" href="#batch-sampling" title="Permalink to this headline">¶</a></h3>
<p>By default, the <code class="code docutils literal notranslate"><span class="pre">run_one_step</span></code> function of the PAL classes will return a <code class="code docutils literal notranslate"><span class="pre">np.ndarray</span></code> with only one index for the point in the design space for which the next experiment should be performed. In some cases, you want to run multiple experiments in batches before you run a new iteration of the PyPAL. In this case, you use the <code class="code docutils literal notranslate"><span class="pre">batch_size</span></code> keyword argument and change it to an integer greater than one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">next_idx</span> <span class="o">=</span> <span class="n">palinstance</span><span class="o">.</span><span class="n">run_one_step</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># next_idx will be a np.array of length 10</span>
</pre></div>
</div>
<p>Of course, also the <cite>exhaust_loop</cite> supports the <cite>batch_size</cite> keyword argument</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">palinstance</span> <span class="o">=</span> <span class="n">PALSklearn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># sample always 10 points and do this until there is no unclassified</span>
<span class="c1"># point left</span>
<span class="n">exhaust_loop</span><span class="p">(</span><span class="n">palinstance</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="caveats-and-tricks-with-gaussian-processes">
<h2>Caveats and tricks with Gaussian processes<a class="headerlink" href="#caveats-and-tricks-with-gaussian-processes" title="Permalink to this headline">¶</a></h2>
<p>One fact that one needs to keep in mind is that <span class="math notranslate nohighlight">\(\epsilon\)</span>-PAL will not work with the predictive variance does not make sense, for example, when the model is overconfident.
This problem is exacerbated in conjunction with <span class="math notranslate nohighlight">\(\beta_\mathrm{scale} &lt; 1\)</span>. To make your model more robust you can try:</p>
<ul class="simple">
<li><p>to set reasonable bounds on the lengthscale parameters</p></li>
<li><p>to increase the regularization parameter/noise kernel <cite>alpha</cite> in <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code></p></li>
<li><p>increase the number of datapoints, especially the coverage of the design space</p></li>
<li><p><a class="reference external" href="https://www.cs.toronto.edu/~duvenaud/cookbook/">to use a kernel that suits your problem</a></p></li>
<li><p>automatic relevance determination (ARD) might increase the predictive performance, but also makes the model more prone to overfitting</p></li>
</ul>
<p>We also recommend to cross-validate your Gaussian process model and to check that the predicted variances make sense.
By default, the code will run a simple cross-validation only on the first iteration and warn if the mean mean absolute error is above the mean standard deviation. If you want to change this behavior and run the cross-validation test more frequently, you can override the <cite>should_run_crossvalidation</cite> function.</p>
</div>
<div class="section" id="implementing-a-new-pal-class">
<h2>Implementing a new PAL class<a class="headerlink" href="#implementing-a-new-pal-class" title="Permalink to this headline">¶</a></h2>
<p>If you want to use <cite>pypal</cite> with a model that we do not support yet, i.e., not <code class="code docutils literal notranslate"><span class="pre">GPy</span></code> or <code class="code docutils literal notranslate"><span class="pre">sklearn</span></code> Gaussian process regression, it is easy to write your own class. For this, you need to inherit from <cite>PALBase</cite> and implement your of <code class="code docutils literal notranslate"><span class="pre">_train</span></code> and <code class="code docutils literal notranslate"><span class="pre">_predict</span></code> functions (and maybe also the <code class="code docutils literal notranslate"><span class="pre">_set_hyperparameters</span></code> and <code class="code docutils literal notranslate"><span class="pre">_should_optimize_hyperparameters</span></code> functions) using the <code class="code docutils literal notranslate"><span class="pre">design_space</span></code> and <code class="code docutils literal notranslate"><span class="pre">y</span></code> attributes of the class.</p>
<p>For instance, if we develop some multioutput model that has a <code class="code docutils literal notranslate"><span class="pre">train()</span></code> and a <code class="code docutils literal notranslate"><span class="pre">predict()</span></code> method we could simply do</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALBase</span>

<span class="k">class</span> <span class="nc">PALMyModel</span><span class="p">(</span><span class="n">PALBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design_space</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design_space</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that we typically provide the models, even if it is only one, in a list to keep the API consistent.</p>
<p>In some instances, you might want to perform an operation in parallel, e.g., train the models for different objectives in parallel. One convenient way to do this in Python is <a class="reference external" href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a>. The only hitch is that this approach requires that the function is picklable. To ensure is, you may want to implement the function that is to be run in parallel outside the class. For example, you could use the following design pattern</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pypal</span> <span class="kn">import</span> <span class="n">PALBase</span>
<span class="kn">import</span> <span class="nn">concurrent.futures</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="k">def</span> <span class="nf">_train_model_picklable</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">design_space</span><span class="p">,</span> <span class="n">objectives</span><span class="p">,</span> <span class="n">sampled</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">design_space</span><span class="p">[</span><span class="n">sampled</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]],</span>
        <span class="n">objectives</span><span class="p">[</span><span class="n">sampled</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">class</span> <span class="nc">MyPal</span><span class="p">(</span><span class="n">PALBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;n_jobs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">validate_njobs</span><span class="p">(</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">validate_number_models</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_single_partial</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">_train_model_picklable</span><span class="p">,</span>
            <span class="n">models</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">design_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">design_space</span><span class="p">,</span>
            <span class="n">objectives</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="n">sampled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span>
            <span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">train_single_partial</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)):</span>
                <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
</pre></div>
</div>
</div>
</div>


              </div>


              <div class='prev-next-bottom'>

    <a class='left-prev' id="prev-link" href="index.html" title="previous page">pypal: Pareto active learning for Python</a>
    <a class='right-next' id="next-link" href="background.html" title="next page">Background</a>

              </div>

          </main>


      </div>
    </div>


  <script src="_static/js/index.30270b6e4c972e43c488.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Kevin Maik Jablonka, Brian Yoo, Berend Smit.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>
